{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4tCVHuXA-6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pycm livelossplot\n",
        "%pylab inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V27x0fxNBdzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from livelossplot import PlotLosses\n",
        "from pycm import *\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6xJblarBkPY",
        "colab_type": "code",
        "outputId": "17872faf-dae1-47cb-eaba-decba9b9688c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = False  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
        "    torch.backends.cudnn.enabled   = False\n",
        "\n",
        "    return True\n",
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No GPU available!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXp_I0TkGYSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json \n",
        "\n",
        "\n",
        "with open(\"/kaggle/input/acse-miniproject/mapping.json\",'r', encoding='UTF-8') as f:\n",
        "     load_dict = json.load(f)\n",
        "\n",
        "\n",
        "train_file = glob.glob('/kaggle/input/acse-miniproject/train/*/images/*.JPEG')\n",
        "print(len(train_file))\n",
        "train_data = []\n",
        "labels = []\n",
        "count = 0\n",
        "\n",
        "\n",
        "for f in train_file:\n",
        "    img = np.array(Image.open(f))\n",
        "    label_name = f.split('/')[5]\n",
        "    label = load_dict.get(label_name)\n",
        "    if img.shape != (64,64,3):\n",
        "        img = np.stack((img,)*3, axis=-1)\n",
        "    \n",
        "    train_data.append(img)\n",
        "    labels.append(label)\n",
        "    count += 1\n",
        "\n",
        "print(len(train_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGQ0bxSzGau_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = np.array(train_data)\n",
        "labels = np.array(labels)\n",
        "print(train_data.shape)\n",
        "print(labels.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17Sv583eGYU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = train_data.mean(axis=(0,1,2))/255\n",
        "std = train_data.std(axis=(0,1,2))/255\n",
        "\n",
        "print(mean)\n",
        "print(std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t9YzGdWGYXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shuffler = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42).split(train_data, labels)\n",
        "\n",
        "indices = [(train_idx, validation_idx) for train_idx, validation_idx in shuffler][0]\n",
        "#valid_idx = list(set(train_idx).difference(set(train_dataset)))\n",
        "\n",
        "print(len(indices[0]))\n",
        "print(len(indices[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mtDhUykGYbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = torch.tensor(train_data[indices[0]]).float(), torch.tensor(labels)[indices[0]]\n",
        "X_val, y_val = torch.tensor(train_data[indices[1]]).float(), torch.tensor(labels)[indices[1]]\n",
        "\n",
        "\n",
        "X_train = X_train.permute(0,3,1,2)\n",
        "X_val = X_val.permute(0,3,1,2)\n",
        "\n",
        "\n",
        "print(X_train.size())\n",
        "print(X_val.size())\n",
        "print(y_train.size())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpMqAlDBGYdq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset \n",
        "\n",
        "class CustomImageTensorDataset(Dataset):\n",
        "    def __init__(self, data, targets, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data (Tensor): A tensor containing the data e.g. images\n",
        "            targets (Tensor): A tensor containing all the labels\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample, label = self.data[idx], self.targets[idx]\n",
        "        #sample = sample.view(3, 64, 63).float()/255.\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "\n",
        "        return sample, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87vpKtdVGYf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transform = torchvision.transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.RandomCrop(224, padding=8),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)])\n",
        "\n",
        "valid_transform = torchvision.transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)])\n",
        "\n",
        "train_set = CustomImageTensorDataset(X_train, y_train.long(), transform=train_transform)\n",
        "valid_set = CustomImageTensorDataset(X_val, y_val.long(), transform=valid_transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6LTsfRwGYh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set hyperparameters\n",
        "\n",
        "seed = 42\n",
        "lr = 1e-2\n",
        "momentum = 0.9\n",
        "batch_size = 64\n",
        "test_batch_size = 1000\n",
        "n_epochs = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ9WpKefGYkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "valid_loader = DataLoader(valid_set, batch_size=test_batch_size, shuffle=False, num_workers=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6eLcSrKGYme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, criterion, data_loader):\n",
        "    model.train() ## the model is in the training mode so the parameters(weights)to be optimised will be updatad at each step\n",
        "    train_loss, train_accuracy = 0, 0\n",
        "    for X, y in data_loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        a2 = model(X.view(-1, 3, 224, 224))\n",
        "        loss = criterion(a2, y)\n",
        "        loss.backward()\n",
        "        train_loss += loss*X.size(0)\n",
        "        y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
        "        train_accuracy += accuracy_score(y.cpu().numpy(), y_pred.detach().cpu().numpy())*X.size(0) ## .cpu cpoies the tensor to the cpu to evaluate the accuracy score since it is a scikitlearn metric which does not run on GPUs\n",
        "        optimizer.step()  \n",
        "        \n",
        "    return train_loss/len(data_loader.dataset), train_accuracy/len(data_loader.dataset)  ## loss and accuracy calculated give the total for all batches and must be divided by the number of batch size to give the average values.\n",
        "\n",
        "def validate(model, criterion, data_loader):\n",
        "    model.eval() ## model is set to evaluation mode to freeze the parameters and ensure weights are not updated at each step so that the trained model is used to evaluate the validation loss\n",
        "    validation_loss, validation_accuracy = 0., 0.\n",
        "    for X, y in data_loader:\n",
        "        with torch.no_grad():\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            a2 = model(X.view(-1, 3, 224, 224))\n",
        "            loss = criterion(a2, y)\n",
        "            validation_loss += loss*X.size(0)\n",
        "            y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
        "            validation_accuracy += accuracy_score(y.cpu().numpy(), y_pred.cpu().numpy())*X.size(0)\n",
        "            \n",
        "    return validation_loss/len(data_loader.dataset), validation_accuracy/len(data_loader.dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIYAJSH5G-6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    ys, y_preds = [], []\n",
        "    for X, y in data_loader:\n",
        "        with torch.no_grad():\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            a2 = model(X.view(-1, 3, 224, 224))\n",
        "            #a2 = model(X.view(-1, 28*28)) #What does this have to look like for our conv-net? Make the changes!\n",
        "            y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
        "            ys.append(y.cpu().numpy())\n",
        "            y_preds.append(y_pred.cpu().numpy())\n",
        "            \n",
        "    return np.concatenate(y_preds, 0),  np.concatenate(ys, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq9f9sc-G-0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        " \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import copy\n",
        "import os\n",
        "\n",
        "plt.ion()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2oZ2lsuG-r6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, num_epochs=30):\n",
        " \n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "    valid_loader = DataLoader(valid_set, batch_size=test_batch_size, shuffle=False, num_workers=0)\n",
        "  \n",
        "    liveloss = PlotLosses()\n",
        "    for epoch in range(num_epochs):\n",
        "        logs = {}\n",
        "        train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
        "\n",
        "        logs['' + 'log loss'] = train_loss.item()\n",
        "        logs['' + 'accuracy'] = train_accuracy.item()\n",
        "\n",
        "        validation_loss, validation_accuracy = validate(model, criterion, valid_loader)\n",
        "        logs['val_' + 'log loss'] = validation_loss.item()\n",
        "        logs['val_' + 'accuracy'] = validation_accuracy.item()\n",
        "\n",
        "        liveloss.update(logs)\n",
        "        liveloss.draw()\n",
        "\n",
        "    return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csMaWIuEHHw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finetuning\n",
        "\n",
        "model_ft = models.resnet18(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 200)\n",
        " \n",
        "if torch.cuda.is_available():\n",
        "    model_ft = model_ft.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        " \n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQsnQ87rHHst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft,\n",
        "                       num_epochs=30)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}