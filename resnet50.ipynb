{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet50.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF5d-1l8xTG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#livelossplot setup\n",
        "!pip install pycm livelossplot\n",
        "%pylab inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHgG1QtaxUQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from livelossplot import PlotLosses\n",
        "from pycm import *\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = False  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
        "    torch.backends.cudnn.enabled   = False\n",
        "\n",
        "    return True\n",
        "\n",
        "# device = 'cpu'\n",
        "device = torch.device(\"cuda:0\")\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2_nf24UxWuN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Other Hyperparameters\n",
        "seed = 42\n",
        "lr = 0.01\n",
        "momentum = 0.9\n",
        "batch_size = 100\n",
        "test_batch_size = 1000\n",
        "n_epochs = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyvYk72PxYey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_path = '/kaggle/input/acse-miniproject/train' #'/content/drive/My Drive/Logistic/train'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjjaWPIDx7oI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json \n",
        "\n",
        "#'/content/drive/My Drive/Logistic/mapping.json'\n",
        "with open(\"/kaggle/input/acse-miniproject/mapping.json\",'r', encoding='UTF-8') as f:\n",
        "     load_dict = json.load(f)\n",
        "\n",
        "\n",
        "train_file = glob.glob(train_data_path+'/*/images/*.JPEG')\n",
        "print(len(train_file))\n",
        "train_data = []\n",
        "labels = []\n",
        "count = 0\n",
        "\n",
        "\n",
        "for f in train_file:\n",
        "    img = np.array(Image.open(f))\n",
        "    label_name = f.split('/')[5] #[6]\n",
        "    label = load_dict.get(label_name)\n",
        "    if img.shape != (64,64,3):\n",
        "        img = np.stack((img,)*3, axis=-1)\n",
        "    \n",
        "    train_data.append(img)\n",
        "    labels.append(label)\n",
        "    count += 1\n",
        "\n",
        "print(len(train_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlEncGS4yK6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = np.array(train_data)\n",
        "labels = np.array(labels)\n",
        "print(train_data.shape)\n",
        "print(labels.shape)\n",
        "\n",
        "# mean = train_data.mean(axis=(0,1,2))/255\n",
        "# std = train_data.std(axis=(0,1,2))/255\n",
        "mean=[0.4802, 0.4481, 0.3975]\n",
        "std=[0.2770, 0.2691, 0.2821]\n",
        "\n",
        "print(mean)\n",
        "print(std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSO0UO47yPYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shuffler = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42).split(train_data, labels)\n",
        "\n",
        "indices = [(train_idx, validation_idx) for train_idx, validation_idx in shuffler][0]\n",
        "#valid_idx = list(set(train_idx).difference(set(train_dataset)))\n",
        "\n",
        "print(len(indices[0]))\n",
        "print(len(indices[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hoDK_C8yQA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = torch.tensor(train_data[indices[0]]).float(), torch.tensor(labels)[indices[0]]\n",
        "X_val, y_val = torch.tensor(train_data[indices[1]]).float(), torch.tensor(labels)[indices[1]]\n",
        "\n",
        "\n",
        "X_train = X_train.permute(0,3,1,2)\n",
        "X_val = X_val.permute(0,3,1,2)\n",
        "\n",
        "\n",
        "print(X_train.size())\n",
        "print(X_val.size())\n",
        "print(y_train.size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nASGxKvNyRil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset \n",
        "\n",
        "class CustomImageTensorDataset(Dataset):\n",
        "    def __init__(self, data, targets, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data (Tensor): A tensor containing the data e.g. images\n",
        "            targets (Tensor): A tensor containing all the labels\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample, label = self.data[idx], self.targets[idx]\n",
        "        #sample = sample.view(3, 64, 63).float()/255.\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "\n",
        "        return sample, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRkJKdtayTED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "\n",
        "train_transform = torchvision.transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.RandomCrop(224, padding=8),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)])\n",
        "\n",
        "valid_transform = torchvision.transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)])\n",
        "\n",
        "train_set = CustomImageTensorDataset(X_train, y_train.long(), transform=train_transform)\n",
        "valid_set = CustomImageTensorDataset(X_val, y_val.long(), transform=valid_transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96coHvJoyWBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SIMPLE SET TO LOADTER\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "valid_loader = DataLoader(valid_set, batch_size=test_batch_size, shuffle=False, num_workers=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruQaZhZkyXc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train + validate + evaluate\n",
        "def train(model, optimizer, criterion, data_loader):\n",
        "    model.train()\n",
        "    train_loss, train_accuracy = 0, 0\n",
        "#     t = 1\n",
        "    for X, y in data_loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "#         a2 = model(X)\n",
        "        a2 = model(X.view(-1, 3, 224, 224)) \n",
        "        loss = criterion(a2, y)\n",
        "        loss.backward()\n",
        "        train_loss += loss*X.size(0)\n",
        "        y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
        "        train_accuracy += accuracy_score(y.cpu().numpy(), y_pred.detach().cpu().numpy())*X.size(0)\n",
        "        optimizer.step()  \n",
        "        \n",
        "    return train_loss/len(data_loader.dataset), train_accuracy/len(data_loader.dataset)\n",
        "  \n",
        "def validate(model, criterion, data_loader):\n",
        "    model.eval()\n",
        "    validation_loss, validation_accuracy = 0., 0.\n",
        "    for X, y in data_loader:\n",
        "        with torch.no_grad():\n",
        "            X, y = X.to(device), y.to(device)\n",
        "#             a2 = model(X)\n",
        "            a2 = model(X.view(-1, 3, 224, 224))\n",
        "            #a2 = model(X.view(-1, 28*28)) #What does this have to look like for our conv-net? Make the changes!\n",
        "            loss = criterion(a2, y)\n",
        "            validation_loss += loss*X.size(0)\n",
        "            y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
        "            validation_accuracy += accuracy_score(y.cpu().numpy(), y_pred.cpu().numpy())*X.size(0)\n",
        "            \n",
        "    return validation_loss/len(data_loader.dataset), validation_accuracy/len(data_loader.dataset)\n",
        "  \n",
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    ys, y_preds = [], []\n",
        "    for X, y in data_loader:\n",
        "        with torch.no_grad():\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            a2 = model(X)\n",
        "            # a2 = model(X.view(-1, 1, 28, 28))\n",
        "            #a2 = model(X.view(-1, 28*28)) #What does this have to look like for our conv-net? Make the changes!\n",
        "            y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
        "            ys.append(y.cpu().numpy())\n",
        "            y_preds.append(y_pred.cpu().numpy())\n",
        "            \n",
        "    return np.concatenate(y_preds, 0),  np.concatenate(ys, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc3R1Mm_ybT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def exp_lr_scheduler(optimizer, epoch, lr_decay=0.1, lr_decay_epoch=2):\n",
        "    \"\"\"Decay learning rate by a factor of lr_decay every lr_decay_epoch epochs\"\"\"\n",
        "    if epoch % lr_decay_epoch:\n",
        "        return optimizer\n",
        "    \n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] *= lr_decay\n",
        "    return optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDZKBDpSyb6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, optimizer, weight_decay = 0., bias = True):\n",
        "    set_seed(seed)\n",
        "#     optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay = weight_decay)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    liveloss = PlotLosses()\n",
        "    for epoch in range(n_epochs):\n",
        "        optimizer = exp_lr_scheduler(optimizer, epoch)\n",
        "#         print(epoch)\n",
        "        train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
        "#         print(train_loss.item(), train_accuracy.item())\n",
        "        logs = {}\n",
        "        logs['' + 'log loss'] = train_loss.item()\n",
        "        logs['' + 'accuracy'] = train_accuracy.item()\n",
        "#     print(train_loss.item(), train_accuracy.item())\n",
        "        validation_loss, validation_accuracy = validate(model, criterion, valid_loader)\n",
        "#         print(validation_loss.item(), validation_accuracy.item())\n",
        "        logs['val_' + 'log loss'] = validation_loss.item()\n",
        "        logs['val_' + 'accuracy'] = validation_accuracy.item()\n",
        "\n",
        "        liveloss.update(logs)\n",
        "        liveloss.draw()\n",
        "\n",
        "    return model, liveloss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPmg-YVaydkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finetuning\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "\n",
        "model_ft = models.resnet50(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 200)\n",
        " \n",
        "if torch.cuda.is_available():\n",
        "    model_ft = model_ft.cuda()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGP3FS3cyfyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del train_file\n",
        "del X_train, y_train, X_val, y_val, shuffler, indices, mean, std, train_data, labels\n",
        "del img, label_name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR2BisR5yhad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=lr, momentum=momentum, weight_decay=1e-4)\n",
        "model_ft = train_model(model_ft, optimizer_ft)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjevW1yIzEj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json \n",
        "data_path='/kaggle/input/acse-miniproject/test/'\n",
        "# test_transform = torchvision.transforms.Compose([\n",
        "#             transforms.ToTensor(),\n",
        "#             transforms.Normalize(mean=[0.4802, 0.4481, 0.3975], std=[0.2770, 0.2691, 0.2821])])\n",
        "# test_dataset = torchvision.datasets.ImageFolder(\n",
        "#         root=data_path,\n",
        "#         transform=test_transform)\n",
        "test_file = glob.glob('/kaggle/input/acse-miniproject/test/images/*.JPEG') #'/content/drive/My Drive/Logistic/train/images/*.JPEG'\n",
        "print(len(test_file))\n",
        "test_data = []\n",
        "test_names = []\n",
        "for f in test_file:\n",
        "    \n",
        "    img = np.array(Image.open(f))\n",
        "    test_name = f.split('/')[6][5:-5] #[7][5:-5] \n",
        "    #label = load_dict.get(label_name)\n",
        "    if img.shape != (64,64,3):\n",
        "        img = np.stack((img,)*3, axis=-1)\n",
        "    test_data.append(img)\n",
        "    test_names.append(int(test_name))\n",
        "print(test_names[:5])\n",
        "#y_test is only used for generating dataset. it's not the real labels\n",
        "y_test = np.array(test_names)\n",
        "y_test = torch.tensor(y_test)\n",
        " \n",
        "X_test = np.array(test_data)\n",
        "X_test = torch.tensor(X_test).float()\n",
        "X_test = X_test.permute(0,3,1,2)\n",
        " \n",
        "test_set = CustomImageTensorDataset(X_test, y_test.long(), transform=valid_transform)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        test_set,\n",
        "        batch_size=1000,\n",
        "        num_workers=0,\n",
        "        shuffle=False\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJm4xWjDzGOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred, y_gt = evaluate(model_ft[0], test_loader)\n",
        "y_pred[:5], y_gt[:5]\n",
        "res = {}\n",
        "for i in range(10000):\n",
        "    res[\"test_\" + str(y_gt[i]) + \".jpeg\"] = y_pred[i]\n",
        "res\n",
        "import csv\n",
        "#'/content/drive/My Drive/Logistic/resnet50.csv'\n",
        "with open('/kaggle/working/resnet50.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Filename\", \"Label\"])\n",
        "    for key, item in res.items():\n",
        "        writer.writerow([key, item])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}